{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#SCRAPER_OUTPUT = \".\\\\tables-metacritic\\\\pages.npy\"\n",
    "#SCRAPER_OUTPUT = \".\\\\tables-rotten\\\\pages.npy\"\n",
    "SCRAPER_OUTPUT = \".\\\\tables-androidword\\\\pages.npy\"\n",
    "\n",
    "#SITENAME = \"Metacritic\"\n",
    "#SITENAME = \"RottenPages\"\n",
    "SITENAME = \"Androidword\"\n",
    "\n",
    "N_CLUSTERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "\n",
    "#carico la tabella di output dello scraper che ha come colonne (tipo_template , url , path_pagina_scaricata)\n",
    "pages = np.load(SCRAPER_OUTPUT)\n",
    "\n",
    "#creo un Dataframe dalla tabella per poterci fare operazioni sopra in maniera agevole con la libreria pandas\n",
    "#df = pd.DataFrame(data=pages)\n",
    "#eliminiamo i duplicati di pagine scaricate (c'era un errore nello scraper che gli faceva scaricare stesse pagine più volte; nella versione finale non ci sarà bisogno di questa operazione)\n",
    "#df = df.drop_duplicates(subset=0, keep=\"last\") \n",
    "#prendo solo i valori del dataframe una volta eliminati i duplicati, in pratica ho la stessa tabella di partenza senza duplicati.\n",
    "#pages = df.values \n",
    "\n",
    "#pages[:,[0, 1]] = pages[:,[1, 0]]\n",
    "\n",
    "#inizializziamo un dataframe DICT vuoto con due colonne soltanto ( url , template); accoglierà su ogni riga una pagina vettorizzata secondo la frequenza dei tag.\n",
    "DICT = pd.DataFrame(columns = [\"url\" , \"template\"]) \n",
    "\n",
    "cc=0\n",
    "#iniziamo a ciclare sulle pagine per fare le nostre analisi\n",
    "for p in pages:\n",
    "    #apriamo il file\n",
    "    with open(p[2], 'r' , encoding=\"UTF-8\") as f:\n",
    "        #leggiamo il file come una stringa\n",
    "        webpage = f.read()\n",
    "        #passiamo la stringa alla libreria per parsare l'html\n",
    "        soup = BeautifulSoup(webpage)      \n",
    "        tags_occurr = []\n",
    "        #contiamo tutti i tag nella pagina\n",
    "        for tag in soup.findAll():\n",
    "            tags_occurr.append(tag.name)      \n",
    "        #creiamo un dataframe dal vettore così ottenuto\n",
    "        tags = pd.DataFrame(data=tags_occurr)\n",
    "        #raggruppiamo i tipi uguali di tag per ottenerne la conta per ciascuno\n",
    "        tags = tags.groupby([0])\n",
    "        grouped_tags = tags.size()\n",
    "        #normalizziamo il vettore così ottenuto\n",
    "        norm = grouped_tags.div(grouped_tags.sum(axis=0), axis=0)        \n",
    "        #creiamo una nuova riga di zeri nel dataframe iniziale globale\n",
    "        DICT.loc[cc] = np.zeros(DICT.shape[1])\n",
    "        #settiamo url e template per la nuova riga\n",
    "        DICT.loc[cc , \"url\"] = p[0]\n",
    "        DICT.loc[cc , \"template\"] = p[1]\n",
    "        #cicliamo il vettore delle tag frequencies e se il tag esiste come colonna ne settiamo il valore\n",
    "        for i in norm.index:\n",
    "            if i in DICT.columns:\n",
    "                DICT.loc[cc , i] = norm[i]\n",
    "        #altrimenti creiamo la nuova colonna con valore di default 0 e settiamo il nuovo valore\n",
    "            else: \n",
    "                DICT.insert(2, i, 0)\n",
    "                DICT.loc[cc , i] = norm[i]\n",
    "    cc += 1\n",
    "    print(cc)\n",
    "    if cc%250 == 0:\n",
    "        print(cc)\n",
    "    #if cc > 150 :\n",
    "    #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decommentare una delle due righe sotto se si vuole salvare o caricare una \"tag frequency matrix\" (il nome che daremo al nostro sistema per clusterizzare)\n",
    "\n",
    "DICT.to_csv(\"TagFrequency-\"+SITENAME+\".csv\" , index=False)\n",
    "#DICT = pd.read_csv('TagFrequency-'+SITENAME+'.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#procediamo con il clustering inizializzando un classificatore kmeans a 3 cluster (dobbiamo classificare 3 templates)\n",
    "\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS)\n",
    "\n",
    "#Prendiamo la nostra matrice delle tag frequencies e togliamo le prime due colonne (corrispondono a url e template)\n",
    "X = DICT.values[:,2:]\n",
    "\n",
    "#avviamo il clustering e otteniamo un vettore che riporterà su ciascuna riga il valore del corrispondente gruppo (template) previsto\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT.values[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi dei risultati del clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#confrontiamo la colonna \"template\" (ha indice 1) della matrice delle frequenze con il vettore ottenuto dal clustering\n",
    "#in entrambi i casi che ho provato sono stato fortunato perchè mi ha assegnato da solo gli stessi valori(0,1,2), in caso contrario devono essere rimappati\n",
    "\n",
    "success = 0\n",
    "for i,t in enumerate(y_kmeans):\n",
    "    if i%250 == 0 :\n",
    "        print(\"confronting index : \"+str(i))\n",
    "    #print(str(i)+\" : \"+str(DICT.values[i,1])+\" confronting with \"+str(t))\n",
    "    if int(DICT.values[i,1]) == int(t) :\n",
    "        success += 1\n",
    "precision = success/len(y_kmeans)\n",
    "print(\"Accuracy : \"+str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueValues = DICT[\"template\"].values\n",
    "trueValues = trueValues.reshape((trueValues.size, 1))\n",
    "y_kmeans = y_kmeans.reshape((y_kmeans.size, 1))\n",
    "results = np.append(trueValues, y_kmeans, axis=1)\n",
    "resultsDF = pd.DataFrame(data=results)\n",
    "resultsDF[0] = pd.to_numeric(resultsDF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsTable = []\n",
    "for c in range(0 , N_CLUSTERS):\n",
    "    rilevati = resultsDF.loc[resultsDF[1] == c][0].size\n",
    "    rilevanti = resultsDF.loc[ (resultsDF[0] == c)][0].size    \n",
    "    rilevanti_rilevati = resultsDF.loc[(resultsDF[0] == c) & (resultsDF[1] == c)][0].size\n",
    "    P = rilevanti_rilevati/rilevati\n",
    "    R = rilevanti_rilevati/rilevanti\n",
    "    resultsTable.append([P , R])\n",
    "    print(\"Precision T\"+str(c)+\" : \"+ str(P))\n",
    "    print(\"Recall T\"+str(c)+\" : \"+ str(R))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtArray = np.array(resultsTable)    \n",
    "np.save(\".\\\\results\\\\\"+SITENAME+\".npy\" , rtArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
